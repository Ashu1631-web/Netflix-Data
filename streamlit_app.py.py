# -*- coding: utf-8 -*-
"""Netflix Data Practice.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E1rTsM7IfKTxsxoqQUabvcJbe89b6LTr
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("/content/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv")
df.head()

df.info()

df.isnull().sum()

df.shape

df.columns

df.duplicated().sum()

df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')

"""## Count of Movies and TV Shows

"""

df['type'].value_counts()

"""### Release Year Movies & TV Shows"""

df['release_year'].value_counts().sort_index()

"""### Top Countries"""

df['country'].value_counts().head(10)

"""### Rating Distribution"""

df['rating'].value_counts()

type_counts = df['type'].value_counts()
type_counts

"""### Bar Graphs (No. Of Movies & TV Show)"""

plt.figure(figsize=(10,6))
plt.bar(type_counts.index, type_counts.values)
plt.xlabel("Content Types")
plt.ylabel("Count")
plt.title("Netflix Movies & Web Series")
plt.show()

"""### Count Plot – Ratings Distribution"""

plt.figure(figsize=(10,6))
sns.countplot(data=df, x='rating', order = df['rating'].value_counts().index)
plt.xticks(rotation=45)
plt.xlabel("Ratings")
plt.ylabel("Count")
plt.title("Ratings Distribution")
plt.show()

"""### Line Plot – Year-wise Trend (Content Added)"""

df['date_added'] = pd.to_datetime(df['date_added'], errors = 'coerce')
df['year_added'] = df['date_added'].dt.year
yearly_content = df['year_added'].value_counts().sort_index()
plt.figure(figsize =(10,6))
plt.plot(yearly_content.index, yearly_content.values, marker = 'o')
plt.xlabel("Year")
plt.ylabel("Number Of Titles Added")
plt.title("Year-wise Trend (Content Added)")
plt.show()

"""### Genre Analysis"""

df['listed_in'].str.split(',').explode().value_counts().head(10)

"""### Duration Analysis"""

# Movies duration
df[df['type']=="Movie"]['duration']

# TV shows seasons
df[df['type']=="TV Show"]['duration']

"""### Principal Components Analysis & Keras"""

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

from sklearn.feature_extraction.text import TfidfVectorizer

# Fill NaN values in 'description' column with an empty string
df['description'] = df['description'].fillna('')

# Initialize TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000) # Limiting features for demonstration

# Fit and transform the 'description' column to create X_tfidf
X_tfidf = tfidf_vectorizer.fit_transform(df['description'])


pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X_tfidf.toarray())
print("PCA Shape", X_pca.shape)

from sklearn.cluster import KMeans

k = 5  # You can choose the desired number of clusters

kmeans = KMeans(n_clusters=k, random_state=42, n_init=10) # n_init is explicitly set to suppress warning
df['cluster'] = kmeans.fit_predict(X_pca)

for i in range(k):
    print(f"\n--- Cluster {i} ---")
    print(df[df['cluster']==i]['listed_in'].value_counts().head(5))